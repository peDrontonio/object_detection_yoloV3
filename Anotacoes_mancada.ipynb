{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301eab73",
   "metadata": {},
   "source": [
    "# Stratified K-Fold para Detecção de Objetos (Formato COCO)\n",
    "\n",
    "Depois de ler o material que você me mandou, implementar a versão padrão (a mais comum) e refletir um pouco, resolvi deixar aqui uma segunda versão do split_data.py. Ainda não dei uma olhada no dataset, então essa proposta é mais baseada em suposições.\n",
    "\n",
    "A ideia de fazer isso é que eu imagino que o motivo pelo qual você queria usar um stratified k-fold não é necessariamente por causa da quantidade de classes diferentes, mas sim pelo número de classes presentes em cada imagem. Suponho que os manômetros estejam agrupados em um mesmo local, o que pode significar pouca variação de tipos entre as imagens, mas uma grande variação na quantidade deles.\n",
    "\n",
    "Então aqui vai uma sugestão de como você poderia implementar essa segunda abordagem. No código, deixei a versão mais simples, que considera apenas as classes presentes na imagem (sem levar em conta o número de instâncias de cada uma, só sua presença).\n",
    "\n",
    "### Primeiro passo: Estabelecer uma função auxiliar que vai separar as imagens pelo número de instâncias da classe. (opcional)\n",
    "\n",
    "ChatGPT e Gemini disseram que não compensa colocar um label pra cada número, mas sim fazer em intervalos pra economizar tempo e poder computacional. Como não sei quão preciso você precisaria ser, deixei aqui só a função exemplo com intervalos, mas pode fazer mais se quiser, o skfold aguenta.\n",
    "\n",
    "Ah, e o motivo de não usar o count do próprio create_kfold_splits é só por facilidade mesmo, querendo ou não uma função separada, pelo menso pra agora que eu não sei quantos intervalos seriam necessários, é mais claro editar uma função auxiliar externa do que mexer na função que você já tinha criado (mas se quiser, dá pra kover lá pra dentro depois)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619615a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_bin(count: int) -> str:\n",
    "    \"\"\"Categoriza uma contagem de objetos em faixas\"\"\"\n",
    "    count = int(count)\n",
    "    if count == 0:\n",
    "        return 'none' # Não deveria acontecer, mas vai que\n",
    "    elif count <= 2:\n",
    "        return 'low'   # 1 a 2 objetos\n",
    "    elif count <= 5:\n",
    "        return 'medium'# 3 a 5 objetos\n",
    "    else:\n",
    "        return 'high'  # 6 ou mais objetos\n",
    "\n",
    "#Pode colocar esse método bem no começo do código se quiser, mas acho que não faz tanta diferença desde que ele seja chamada antes do uso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d532c3",
   "metadata": {},
   "source": [
    "### Segundo passo: mudar o create_kfold_splits_with_dataframe (Editar a chave de estraficação)\n",
    "\n",
    "Assim como tá implementado atualmente a chave de estratificação (que é que cria essas novas labels pro kfold com as diversas classes), precisamos alterá-la para ela ser capaz de receber esse fato da quantidade. Se esse método que eu tô apresentando agora for no fim o preferido, é só copiar o que tá aqui em baixo e substituir todo o trecho da chave de estratificação atual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9923d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kfold_splits_with_dataframe(...):\n",
    "    [...]\n",
    "    #Toda a parte do class count dataframe\n",
    "    [...]\n",
    "    stratify_keys_list = []\n",
    "    # Itera sobre cada imagem no DataFrame\n",
    "    for _, row in labels_df.iterrows(): #Não sei se pode tirar o \"_\" e substituir por algo mais informativo, então deixei assim (Até onde compreendo, o pandas não precisa) \n",
    "        key_parts = []\n",
    "        # Pega apenas as classes que estão presentes na imagem\n",
    "        present_classes = row[row > 0]\n",
    "\n",
    "        if present_classes.empty:\n",
    "            stratify_keys_list.append('empty')\n",
    "            continue\n",
    "\n",
    "        # Para cada classe presente, cria uma chave 'classe_faixa', ou seja, conta e coloca naqueles intervalos pré-definidos (low, medium, high)\n",
    "        for class_name, count in present_classes.items():\n",
    "            bin_name = get_count_bin(count)\n",
    "            key_parts.append(f\"{class_name}_{bin_name}\")\n",
    "        \n",
    "        # Ordena as partes para garantir consistência (fazer com que a ordem dos fatores (labels) não afete o produto final (deixa as labels iguais))\n",
    "        key_parts.sort()\n",
    "        stratify_keys_list.append('_'.join(key_parts))\n",
    "    \n",
    "    # Converte a lista de chaves para uma Série pandas para usar no split\n",
    "    stratify_key = pd.Series(stratify_keys_list, index=labels_df.index)\n",
    "\n",
    "    logger.info(\"Stratification key created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9543b",
   "metadata": {},
   "source": [
    "### Passo três: Ir pro abraço!!\n",
    "\n",
    "O resto segue como já estava, ou seja, você rodaria o skfold como já está lá com os novos argumentos e reza pra dar certo (não precisa mexer em mais nada, a não ser naquele k no começo do código que está setado como 0 no momento).\n",
    "\n",
    "Como ficou o código em geral então:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_count_bin(count: int) -> str:\n",
    "    \"\"\"\n",
    "    Counts the number of objects in each image and categorizes them into bins.\n",
    "    \"\"\"\n",
    "    count = int(count)\n",
    "    if count == 0:\n",
    "        return 'none' \n",
    "    elif count <= 2:\n",
    "        return 'low'   \n",
    "    elif count <= 5:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'  \n",
    "    \n",
    "def split_data(images_dir, coco_json_path, output_dir, \n",
    "               train_ratio=0.75, val_ratio=0.1, ablation=0, k=0, pose_estimation=False,\n",
    "               rename_images=False, classes=[]):\n",
    "    \"\"\"\n",
    "    Splits a COCO dataset into training, validation, and testing sets or creates k-fold splits.\n",
    "    \"\"\"\n",
    "    logger.info(\"Loading COCO annotations...\")\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    images_dir = Path(images_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    if not images_dir.exists():\n",
    "        logger.error(f\"Images directory does not exist: {images_dir}\")\n",
    "        return\n",
    "    \n",
    "    if classes:\n",
    "        coco_data = filter_coco_by_classes(coco_data, classes)\n",
    "\n",
    "    images = coco_data.get('images', [])\n",
    "    annotations = coco_data.get('annotations', [])\n",
    "    categories = coco_data.get('categories', [])\n",
    "\n",
    "    logger.info(f\"Total annotated images: {len(images)}\")\n",
    "    logger.info(f\"Total annotated objects: {len(annotations)}\")\n",
    "\n",
    "    if k > 0:\n",
    "        create_kfold_splits_with_dataframe(images, annotations, categories, images_dir, output_dir, k, rename_images, pose_estimation)\n",
    "    elif ablation > 0:\n",
    "        splits = generate_splits(images, train_ratio, val_ratio, ablation)\n",
    "        process_splits(splits, images_dir, annotations, categories, output_dir, rename_images, pose_estimation)\n",
    "    else:\n",
    "        splits = generate_splits(images, train_ratio, val_ratio, ablation=0)\n",
    "        process_splits(splits, images_dir, annotations, categories, output_dir, rename_images, pose_estimation)\n",
    "\n",
    "def create_kfold_splits_with_dataframe(images, annotations, categories, images_dir, output_dir, k, rename_images, pose_estimation):\n",
    "    \"\"\"\n",
    "    Create k-fold splits for the dataset using a pandas DataFrame of class counts per image.\n",
    "    \"\"\"\n",
    "    logger.info(\"Creating class count DataFrame...\")\n",
    "\n",
    "    # Create a mapping from image IDs to their file names\n",
    "    image_id_to_filename = {image['id']: image['file_name'] for image in images}\n",
    "\n",
    "    # Create a mapping from category IDs to their names\n",
    "    category_id_to_name = {category['id']: category['name'] for category in categories}\n",
    "\n",
    "    # Initialize a DataFrame\n",
    "    index = [image['file_name'] for image in images]  # Use image file names as index\n",
    "    labels_df = pd.DataFrame(0, columns=category_id_to_name.values(), index=index)\n",
    "\n",
    "    # Populate the DataFrame with object counts per class for each image\n",
    "    for annotation in annotations:\n",
    "        image_id = annotation['image_id']\n",
    "        category_id = annotation['category_id']\n",
    "\n",
    "        if image_id in image_id_to_filename:\n",
    "            image_name = image_id_to_filename[image_id]\n",
    "            class_name = category_id_to_name[category_id]\n",
    "            labels_df.loc[image_name, class_name] += 1\n",
    "\n",
    "    labels_df = labels_df.fillna(0)  # Replace NaN values with 0\n",
    "    logger.info(\"Class count DataFrame created.\")\n",
    "\n",
    "    logger.info(\"Creating stratification key for k-fold splitting...\")\n",
    "    stratify_keys_list = []\n",
    "    for _, row in labels_df.iterrows():\n",
    "        key_parts = []\n",
    "        # Gets only the classes that are present in the image\n",
    "        present_classes = row[row > 0]\n",
    "\n",
    "        if present_classes.empty:\n",
    "            stratify_keys_list.append('empty')\n",
    "            continue\n",
    "\n",
    "        # For each class, crate a key 'classname_countbin'\n",
    "        for class_name, count in present_classes.items():\n",
    "            bin_name = get_count_bin(count)\n",
    "            key_parts.append(f\"{class_name}_{bin_name}\")\n",
    "        \n",
    "        # Orders the parts to ensure consistency\n",
    "        key_parts.sort()\n",
    "        stratify_keys_list.append('_'.join(key_parts))\n",
    "    \n",
    "    # Convert the list of keys to a pandas Series for use in the split\n",
    "    stratify_key = pd.Series(stratify_keys_list, index=labels_df.index)\n",
    "    logger.info(\"Stratification key created.\")\n",
    "\n",
    "    # Perform stratified k-fold splitting\n",
    "    skfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42) \n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skfold.split(labels_df, stratify_key)):\n",
    "        fold_name = f\"fold_{fold+1}\"\n",
    "        logger.info(f\"Processing {fold_name}...\")\n",
    "\n",
    "        # Get the training and validation file names\n",
    "        train_files = labels_df.index[train_idx].tolist()\n",
    "        val_files = labels_df.index[val_idx].tolist()\n",
    "\n",
    "        # Filter images and annotations for each split\n",
    "        train_images = [img for img in images if img['file_name'] in train_files]\n",
    "        val_images = [img for img in images if img['file_name'] in val_files]\n",
    "\n",
    "        train_annotations = filter_annotations(train_images, annotations, pose_estimation)\n",
    "        val_annotations = filter_annotations(val_images, annotations, pose_estimation)\n",
    "\n",
    "        # Prepare directories\n",
    "        # train_images_path = output_dir / fold_name / \"images\" \n",
    "        # val_images_path = output_dir / fold_name / \"images\" \n",
    "\n",
    "        train_images_path = output_dir / fold_name / \"images\" / \"train\"\n",
    "        train_labels_path = output_dir / fold_name / \"labels\" / \"train\"\n",
    "        val_images_path = output_dir / fold_name / \"images\" / \"val\"\n",
    "        val_labels_path = output_dir / fold_name / \"labels\" / \"val\"\n",
    "        \n",
    "        train_images_path.mkdir(parents=True, exist_ok=True)\n",
    "        train_labels_path.mkdir(parents=True, exist_ok=True)\n",
    "        val_images_path.mkdir(parents=True, exist_ok=True)\n",
    "        val_labels_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Copy images and create subsets\n",
    "        train_updated_images = copy_images(train_images, images_dir, train_images_path, rename_images)\n",
    "        val_updated_images = copy_images(val_images, images_dir, val_images_path, rename_images)\n",
    "\n",
    "        train_coco = create_coco_subset(train_updated_images, train_annotations, categories)\n",
    "        val_coco = create_coco_subset(val_updated_images, val_annotations, categories)\n",
    "\n",
    "        # Save JSON files\n",
    "        with open(train_labels_path / \"coco.json\", 'w') as f:\n",
    "            json.dump(train_coco, f, indent=4)\n",
    "        with open(val_labels_path / \"coco.json\", 'w') as f:\n",
    "            json.dump(val_coco, f, indent=4)\n",
    "\n",
    "        logger.info(f\"{fold_name} split completed.\")\n",
    "\n",
    "def process_splits(splits, images_dir, annotations, categories, output_dir, rename_images, pose_estimation):\n",
    "    \"\"\"\n",
    "    Process and save splits for training, validation, and testing.\n",
    "    \"\"\"\n",
    "    for split_name, images_set in splits.items():\n",
    "        try:\n",
    "            # Create directories\n",
    "            images_output_path = output_dir / \"images\" / split_name\n",
    "            labels_output_path = output_dir / \"labels\" / split_name\n",
    "            images_output_path.mkdir(parents=True, exist_ok=True)\n",
    "            labels_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Copy images and create COCO subset\n",
    "            updated_images = copy_images(images_set, images_dir, images_output_path, rename_images)\n",
    "            filtered_annotations = filter_annotations(updated_images, annotations, pose_estimation)\n",
    "            coco_subset = create_coco_subset(updated_images, filtered_annotations, categories)\n",
    "\n",
    "            # Save COCO JSON\n",
    "            with open(labels_output_path / \"coco.json\", 'w') as file:\n",
    "                json.dump(coco_subset, file, indent=4)\n",
    "\n",
    "            # Save metadata\n",
    "            save_metadata(output_dir, split_name, coco_subset)\n",
    "\n",
    "            logger.info(f\"Dataset for {split_name} saved successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to process data for {split_name}: {e}\")\n",
    "\n",
    "def generate_splits(images, train_ratio, val_ratio, ablation):\n",
    "    \"\"\"\n",
    "    Generates a dictionary mapping split names to image lists based on given ratios and ablation settings.\n",
    "    \"\"\"\n",
    "    random.shuffle(images)\n",
    "    total_images = len(images)\n",
    "\n",
    "    if ablation > 0:\n",
    "        val_size = int(total_images * val_ratio)\n",
    "        val_images = images[:val_size]\n",
    "        ablation_images = images[val_size:]\n",
    "\n",
    "        ablation_chunks = [int(len(ablation_images) * (i + 1) / ablation) for i in range(ablation)]\n",
    "        splits = {\"val\": val_images}\n",
    "        for i, chunk_size in enumerate(ablation_chunks):\n",
    "            percentage = f\"{int((chunk_size / len(images)) * 100)}%\"\n",
    "            splits[percentage] = ablation_images[:chunk_size]\n",
    "    else:\n",
    "        train_end = int(total_images * train_ratio)\n",
    "        val_end = train_end + int(total_images * val_ratio)\n",
    "\n",
    "        splits = {\n",
    "            \"train\": images[:train_end],\n",
    "            \"val\": images[train_end:val_end],\n",
    "            \"test\": images[val_end:],\n",
    "        }\n",
    "\n",
    "    return splits\n",
    "\n",
    "def copy_images(images, src_dir, dest_dir, rename_images, name_padding=5):\n",
    "    \"\"\"\n",
    "    Copy selected images to a specified directory, and optionally rename them with new numerical IDs.\n",
    "    Update the images' filenames in the dataset metadata if renamed.\n",
    "    \"\"\"\n",
    "\n",
    "    id_format = f\"{{:0{str(name_padding)}d}}\"\n",
    "\n",
    "    updated_images = []\n",
    "    for image in images:\n",
    "        try:\n",
    "            image_path = Path(image['file_name'])\n",
    "\n",
    "            if rename_images:\n",
    "                if image_path.suffix in ['.jpg', '.jpeg']:\n",
    "                    image_name = image_path.stem + '.jpeg'\n",
    "                else:\n",
    "                    image_name = image_path.name\n",
    "               \n",
    "                # If rename_images is True, rename files using numerical IDs\n",
    "                new_file_name = id_format.format(image[\"id\"]) + \".\" + image_name.split(\".\")[-1]\n",
    "\n",
    "                # Update the image metadata to reflect the new filename\n",
    "                updated_image = image.copy()\n",
    "                updated_image['file_name'] = new_file_name\n",
    "                updated_images.append(updated_image)\n",
    "           \n",
    "            else:\n",
    "                updated_images = images\n",
    "            \n",
    "            src_path = Path(src_dir) / image['file_name']\n",
    "            dest_path = Path(dest_dir) / new_file_name\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            logger.debug(f\"Successfully copied {src_path} to {dest_path}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to copy {src_path} to {dest_path}: {e}\")\n",
    "\n",
    "    return updated_images\n",
    "\n",
    "def filter_annotations(images_set, annotations, pose_estimation):\n",
    "    \"\"\"\n",
    "    Filter annotations to include only those for the provided image set.\n",
    "    \"\"\"\n",
    "    image_ids = {image['id'] for image in images_set}\n",
    "    if pose_estimation:\n",
    "        return [annotation for annotation in annotations if annotation['image_id'] in image_ids and 'keypoints' in annotation]\n",
    "    else:\n",
    "        return [annotation for annotation in annotations if annotation['image_id'] in image_ids]\n",
    "\n",
    "def filter_coco_by_classes(coco_data, classes):\n",
    "    \"\"\"\n",
    "    Filters the COCO data to only include specified classes.\n",
    "    \"\"\"\n",
    "    category_name_to_id = {category['name']: category['id'] for category in coco_data['categories']}\n",
    "\n",
    "    selected_category_ids = [category_name_to_id[name] for name in classes if name in category_name_to_id]\n",
    "\n",
    "    if not selected_category_ids:\n",
    "        logger.error(f\"No matching categories found for classes: {classes}\")\n",
    "        raise ValueError(f\"No matching categories found for classes: {classes}\")\n",
    "\n",
    "    filtered_annotations = [annotation for annotation in coco_data['annotations'] if annotation['category_id'] in selected_category_ids]\n",
    "\n",
    "    image_ids = {annotation['image_id'] for annotation in filtered_annotations}\n",
    "\n",
    "    filtered_images = [image for image in coco_data['images'] if image['id'] in image_ids]\n",
    "\n",
    "    filtered_categories = [category for category in coco_data['categories'] if category['id'] in selected_category_ids]\n",
    "\n",
    "    filtered_coco_data = {\n",
    "        'images': filtered_images,\n",
    "        'annotations': filtered_annotations,\n",
    "        'categories': filtered_categories\n",
    "    }\n",
    "\n",
    "    return filtered_coco_data\n",
    "\n",
    "def create_coco_subset(images, annotations, categories):\n",
    "    \"\"\"\n",
    "    Create a COCO-formatted subset from images, annotations, and categories.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'images': images,\n",
    "        'annotations': annotations,\n",
    "        'categories': categories\n",
    "    }\n",
    "\n",
    "def log_object_count_per_class(coco_data):\n",
    "    \"\"\"\n",
    "    Logs the total number of objects for each class in the COCO dataset.\n",
    "    \"\"\"\n",
    "    category_counts = {category['name']: 0 for category in coco_data['categories']}\n",
    "    for annotation in coco_data['annotations']:\n",
    "        category_id = annotation['category_id']\n",
    "        category_name = next((cat['name'] for cat in coco_data['categories'] if cat['id'] == category_id), None)\n",
    "        if category_name:\n",
    "            category_counts[category_name] += 1\n",
    "\n",
    "    logger.info(\"Object counts per class:\")\n",
    "    for category, count in category_counts.items():\n",
    "        logger.info(f\"  {category}: {count}\")\n",
    "    return category_counts\n",
    "\n",
    "def save_metadata(output_dir, split_name, coco_subset):\n",
    "    \"\"\"\n",
    "    Save metadata, such as class-wise object counts, to a text file.\n",
    "    \"\"\"\n",
    "    chunk_category_counts = log_object_count_per_class(coco_subset)\n",
    "    meta_file_path = output_dir / f\".{split_name}_meta.txt\"\n",
    "    with open(meta_file_path, 'w') as meta_file:\n",
    "        meta_file.write(\"Class-wise Object Counts:\\n\")\n",
    "        for category, count in chunk_category_counts.items():\n",
    "            meta_file.write(f\"{category}: {count}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Split COCO dataset into training, validation, testing sets or k-fold splits.\")\n",
    "    parser.add_argument(\"images_dir\", help=\"Path to the input directory containing images.\")\n",
    "    parser.add_argument(\"coco_json_path\", help=\"Path to the COCO JSON file containing annotations.\")\n",
    "    parser.add_argument(\"output_dir\", help=\"Path to the root output directory for splits.\")\n",
    "    parser.add_argument(\"--k\", type=int, default=0, help=\"Number of folds for k-fold cross-validation (default: 0, i.e., no k-fold split).\")\n",
    "    parser.add_argument(\"--train_ratio\", type=float, default=0.75, help=\"Proportion of images for training\")\n",
    "    parser.add_argument(\"--val_ratio\", type=float, default=0.1, help=\"Proportion of images for validation\")\n",
    "    parser.add_argument(\"--ablation\", type=int, default=0, help=\"Number of dataset chunks for ablation testing\")\n",
    "    parser.add_argument(\"--rename_images\", action=\"store_true\", default=True, help=\"Assign new numerical IDs to image file names\")\n",
    "    parser.add_argument(\"--classes\", nargs='+', default=[], help=\"List of class names to process (default: all classes)\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    split_data(\n",
    "        images_dir=args.images_dir,\n",
    "        coco_json_path=args.coco_json_path,\n",
    "        output_dir=args.output_dir,\n",
    "        train_ratio=args.train_ratio,\n",
    "        val_ratio=args.val_ratio,\n",
    "        ablation=args.ablation,\n",
    "        k=args.k,\n",
    "        rename_images=args.rename_images,\n",
    "        classes=args.classes\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd3663",
   "metadata": {},
   "source": [
    "### OBS: Essa implementação, como eu tinha falado no começo, não compensa se tiver muitas classes únicas\n",
    "Então, se quiser verificar se isso isso é eficiente, dá pra rodar um:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb179c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logo abaixo da chave de estratificação\n",
    "logger.info(\"Top 5 estratos mais comuns com sua contagem:\")\n",
    "logger.info(\"\\n\" + str(stratify_key.value_counts().head(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d1457",
   "metadata": {},
   "source": [
    "E aí você olha se tem bastante imagens ou empty, ou com sla, manometro_digital_high. Se tiver muitos lows, quer dizer que não compensa o trabalho computacional, ou seja, podemos deixar no método padrão que ele já vai fazer a divisão proporcional, e a chave do random (no caso 42) vai provavelmente separar uma quantidade semelhante para cada fold (dado que o dataset é grande o suficiente)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
